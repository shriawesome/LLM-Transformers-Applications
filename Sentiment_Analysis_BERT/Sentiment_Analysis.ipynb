{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/skendre/miniconda3/envs/tfms/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/skendre/miniconda3/envs/tfms/lib/python3.8/site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/skendre/miniconda3/envs/tfms/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/skendre/miniconda3/envs/tfms/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 122] Disk quota exceeded\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip unins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing duplicate entries as we can see SentenceId to have multiple values\n",
    "df.drop_duplicates(subset=['SentenceId'], keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's keep the duplicates as it is since it drastically reduces the dataset size\n",
    "# Checking the distribution of data\n",
    "# df['Sentiment'].value_counts().plot(kind='bar')\n",
    "sns.countplot(x='Sentiment',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of samples we want and the maximum seq length\n",
    "seq_len, num_samples = 512, len(df)\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Converting 'Phrase' text to numerical values\n",
    "tokens = tokenizer(df['Phrase'].tolist(), max_length=seq_len,\n",
    "                    truncation=True,\n",
    "                    padding='max_length',\n",
    "                    add_special_tokens=True,\n",
    "                    return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different elements in the token\n",
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the numpy arrays for later use\n",
    "with open('../data/movie-xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "\n",
    "with open('../data/movie-xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the labels\n",
    "y_train = df['Sentiment'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting it into 1-hot encoding\n",
    "labels = np.zeros((num_samples, y_train.max()+1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting 1 at respective places, for all the rows make that respective value at index to 1\n",
    "labels[np.arange(num_samples),y_train] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/movie-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved numpy array\n",
    "with open('../data/movie-xids.npy', 'rb') as f:\n",
    "    x_ids = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('../data/movie-xmask.npy', 'rb') as f:\n",
    "    x_mask = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('../data/movie-labels.npy', 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156060, 512), (156060, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ids.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((512,), (512,), (5,)), types: (tf.int64, tf.int64, tf.float64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_ids, x_mask, labels))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (512,), attention_mask: (512,)}, (5,)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.float64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping input_ids and attention mask together and labels\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': masks}, labels\n",
    "\n",
    "dataset = dataset.map(map_func)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (16, 512), attention_mask: (16, 512)}, (16, 5)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.float64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the data, Batch and Split\n",
    "batch_size = 16\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8778"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data, 90% train and 10% test\n",
    "split = 0.9\n",
    "size = int((x_ids.shape[0] / batch_size)*split)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "   'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       "  TensorSpec(shape=(16, 5), dtype=tf.float64, name=None)),\n",
       " ({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "   'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       "  TensorSpec(shape=(16, 5), dtype=tf.float64, name=None)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n",
    "train_ds.element_spec, val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 16:12:53.212792: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-09-19 16:12:53.217186: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Saving the data\n",
    "tf.data.experimental.save(train_ds, 'train')\n",
    "tf.data.experimental.save(val_ds, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the save data\n",
    "train_ds = tf.data.experimental.load('train', train_ds.element_spec)\n",
    "test_ds = tf.data.experimental.load('val', val_ds.element_spec)\n",
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building and Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "bert = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define frame around the bert, we need:\n",
    "1. Two input layers to the transformer i.e. the input_ids and the attention mask.\n",
    "2. A post-bert dropout layer to reduce the likelihood of overfitting and improve generalization.\n",
    "3. Max pooling layer to convert the 3D tensors output by BERT to 2D.\n",
    "4. Final output activations using softmax for outputting categorical probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # two input layers\n",
    "    input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "    mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "    # using transformes within our bert object\n",
    "    embeddings = bert.bert(input_ids, attention_mask=mask)[1]\n",
    "\n",
    "    # Convert bert into 5 object class\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "    y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)\n",
    "    \n",
    "    # Initializing optimizer and loss\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=1e-5, decay=1e-6)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "    auc, prec, recall = tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "    \n",
    "    # Initializing the model\n",
    "    model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                 loss = loss,\n",
    "                 metrics=[acc, auc, prec, recall])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrikantkendre/miniforge3/envs/tfM1/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         787456      ['bert[1][1]']                   \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 5)            5125        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 109,102,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/q6/43vsmv9x2pz_q1psr6pkrlyh0000gn/T/ipykernel_942/695456006.py:6: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
    "   'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
    "  tf.TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))\n",
    "\n",
    "train_ds = tf.data.experimental.load('train', element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load('val', element_spec=element_spec)\n",
    "\n",
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 16:24:45.015604: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-20 16:24:47.977569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 124/8778 [..............................] - ETA: 44:24:06 - loss: 1.2000 - categorical_accuracy: 0.5242 - auc: 0.8104 - precision: 0.6763 - recall: 0.3548"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfM1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   validation_data = val_ds,\n",
    "                   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfms",
   "language": "python",
   "name": "tfms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5760e285d1f07ff295f3309a75a929216a45bd81dcf474e6800b0334599a06e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
