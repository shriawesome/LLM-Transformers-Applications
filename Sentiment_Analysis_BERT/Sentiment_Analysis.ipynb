{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase   \n",
       "0         1           1  A series of escapades demonstrating the adage ...  \\\n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing duplicate entries as we can see SentenceId to have multiple values\n",
    "df.drop_duplicates(subset=['SentenceId'], keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's keep the duplicates as it is since it drastically reduces the dataset size\n",
    "# Checking the distribution of data\n",
    "# df['Sentiment'].value_counts().plot(kind='bar')\n",
    "sns.countplot(x='Sentiment',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Labels:\n",
    "* 0 - negative\n",
    "* 1 - somewhat negative\n",
    "* 2 - neutral\n",
    "* 3 - somewhat positive\n",
    "* 4 - positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of samples we want and the maximum seq length\n",
    "seq_len, num_samples = 512, len(df)\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Converting 'Phrase' text to numerical values\n",
    "# add_special_tokens adds special token like 0 : padding, \n",
    "# 101 : [CLS] - Classification etc\n",
    "tokens = tokenizer(df['Phrase'].tolist(), max_length=seq_len,\n",
    "                    truncation=True,\n",
    "                    padding='max_length',\n",
    "                    add_special_tokens=True,\n",
    "                    return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different elements in the token\n",
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Understanding `input_ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 512)\n",
      "Input to BERT decoded:\n",
      "[CLS] A series of escapades demonstrating the adage that what is good for the goose is also good for the gander, some of which occasionally amuses but none of which amounts to much of a story. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  101,   138,  1326,  1104, 13936, 25265, 16913, 15107,  1103,\n",
       "        8050,  2553,  1115,  1184,  1110,  1363,  1111,  1103, 20398,\n",
       "        1110,  1145,  1363,  1111,  1103,   176,  9900,   117,  1199,\n",
       "        1104,  1134,  5411,  1821, 14225,  1133,  3839,  1104,  1134,\n",
       "        7919,  1106,  1277,  1104,   170,  1642,   119,   102,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring different key values\n",
    "# input_ids contain the encoding done for the input sentences\n",
    "print(tokens['input_ids'].shape)\n",
    "print(f\"Input to BERT decoded:\\n{tokenizer.decode(tokens['input_ids'][0][:100])}\")\n",
    "tokens['input_ids'][0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding `token_type_ids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some model performs seqeunce classification or QnA.\n",
    "* Thus requires 2 different sequences to be joined in single input_ids.\n",
    "* Usually done as `[CLS] SEQ_A [SEP] SEQ_B [SEP]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (156060, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"shape : {tokens['token_type_ids'].shape}\")\n",
    "tokens['token_type_ids'][0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2 sequence it would return say [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding `attention_mask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Used when batching sequence together\n",
    "* This tells the model which tokens to be attended to and which should not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask'][0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 indicates the value to be attended<br>\n",
    "0(pad) indicates the values not be attended**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the numpy arrays for later use\n",
    "with open('data/movie-xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "\n",
    "with open('data/movie-xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the labels\n",
    "y_train = df['Sentiment'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting it into 1-hot encoding\n",
    "labels = np.zeros((num_samples, y_train.max()+1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting 1 at respective places, \n",
    "# for all the rows make that respective value at index to 1\n",
    "labels[np.arange(num_samples),y_train] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/movie-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved numpy array\n",
    "with open('data/movie-xids.npy', 'rb') as f:\n",
    "    x_ids = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('data/movie-xmask.npy', 'rb') as f:\n",
    "    x_mask = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('data/movie-labels.npy', 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156060, 512), (156060, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ids.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_ids, x_mask, labels))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping input_ids and attention mask together and labels\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': masks}, labels\n",
    "\n",
    "dataset = dataset.map(map_func)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the data, Batch and Split\n",
    "batch_size = 16\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data, 90% train and 10% test\n",
    "split = 0.9\n",
    "size = int((x_ids.shape[0] / batch_size)*split)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "   'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       "  TensorSpec(shape=(16, 5), dtype=tf.float64, name=None)),\n",
       " ({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "   'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       "  TensorSpec(shape=(16, 5), dtype=tf.float64, name=None)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n",
    "train_ds.element_spec, val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20879/164082160.py:2: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "# Saving the data\n",
    "tf.data.experimental.save(train_ds, 'train')\n",
    "tf.data.experimental.save(val_ds, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20879/442476633.py:2: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the save data\n",
    "train_ds = tf.data.experimental.load('train', train_ds.element_spec)\n",
    "test_ds = tf.data.experimental.load('val', val_ds.element_spec)\n",
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building and Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "bert = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define frame around the bert, we need:\n",
    "1. Two input layers to the transformer i.e. the input_ids and the attention mask.\n",
    "2. A post-bert dropout layer to reduce the likelihood of overfitting and improve generalization.\n",
    "3. Max pooling layer to convert the 3D tensors output by BERT to 2D.\n",
    "4. Final output activations using softmax for outputting categorical probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # two input layers\n",
    "    input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "    mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "    # using transformes within our bert object\n",
    "    embeddings = bert.bert(input_ids, attention_mask=mask)[1]\n",
    "\n",
    "    # Convert bert into 5 object class\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "    y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)\n",
    "    \n",
    "    # Initializing optimizer and loss\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=1e-5, decay=1e-6)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "    auc, prec, recall = tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "    \n",
    "    # Initializing the model\n",
    "    model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "    # input_ids is layer 1, attention_mask is layer 2 and bert is layer 3, thus setting\n",
    "    # layer 2 trainable be false drastically reduces the training time. Freezes bert layer\n",
    "    model.layers[2].trainable = False\n",
    "    model.compile(optimizer = optimizer,\n",
    "                 loss = loss,\n",
    "                 metrics=[acc, auc, prec, recall])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 5)            5125        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 109,102,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         787456      ['bert[1][1]']                   \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 5)            5125        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 792,581\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we freeze the training of the BERT layer is drastically reduces the training params and also speeds up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
    "   'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
    "  tf.TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))\n",
    "\n",
    "train_ds = tf.data.experimental.load('train', element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load('val', element_spec=element_spec)\n",
    "\n",
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  22/8778 [..............................] - ETA: 16:13:06 - loss: 1.4383 - categorical_accuracy: 0.4744 - auc_1: 0.6970 - precision_1: 0.5000 - recall_1: 0.0597     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/raid/skendre/miniconda3/envs/tfms/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   validation_data = val_ds,\n",
    "                   epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfms",
   "language": "python",
   "name": "tfms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5760e285d1f07ff295f3309a75a929216a45bd81dcf474e6800b0334599a06e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
